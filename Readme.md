DEMO

https://github.com/user-attachments/assets/bbaf4d7f-d14c-4b7e-a9ba-f47f41732218

# Customer Support Voice RAG Agent ðŸŽ™ï¸

Real-time voice-enabled customer support agent using **Gemini LLM**, **Deepgram STT**, **Cartesia TTS**, and **LlamaIndex RAG**. Features continuous listening, push-to-talk, and WebSocket-based real-time communication.

![Python](https://img.shields.io/badge/python-3.8+-blue?style=flat-square) ![Flask](https://img.shields.io/badge/flask-socketio-red?style=flat-square) ![Status](https://img.shields.io/badge/status-production--ready-green?style=flat-square)

## ðŸš€ Quick Start

### Prerequisites
- Python 3.8+
- **Google API Key** (Gemini - FREE)
- **Deepgram API Key** (Speech-to-Text)
- **Cartesia API Key** (Text-to-Speech)

### Installation


# 1. Clone & setup
git clone https://github.com/Jawadbro/customer-support-voice-rag-agent.git
cd customer-support-voice-rag-agent
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 2. Install dependencies
pip install flask flask-socketio python-dotenv llama-index
pip install google-generativeai requests pydantic numpy
pip install pymupdf pdfplumber

# 3. Create .env file
cat > .env << EOL
GOOGLE_API_KEY=your_google_api_key
DEEPGRAM_API_KEY=your_deepgram_key
CARTESIA_API_KEY=your_cartesia_key
CARTESIA_VOICE_ID=your_voice_id
EOL

# 4. Add documents to data/ folder (optional - car.txt already included)

# 5. Run
python app.py


Open **http://localhost:5000** in your browser.

## ðŸ“ Project Structure

```
â”œâ”€â”€ app.py                         # Main application
â”œâ”€â”€ .env                          # API keys
â”œâ”€â”€ data/
â”‚   â””â”€â”€ car.txt                   # Knowledge base documents
â””â”€â”€ query-engine-storage-free/    # Vector store (auto-generated)
```

## ðŸŽ¤ Usage

**Voice Modes:**
- **Continuous Listening**: Click "Start Continuous Listening" - speak naturally
- **Push-to-Talk**: Hold button while speaking
- **Text Input**: Type questions directly

**Adding Documents:**
- Drop PDF, TXT, DOCX, HTML, MD files in `data/` folder
- Delete `query-engine-storage-free/` and restart to rebuild knowledge base

## âš¡ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Browser   â”‚â”€â”€â”€â–¶â”‚  Flask-SocketIO  â”‚â”€â”€â”€â–¶â”‚   Audio Buffer  â”‚
â”‚   (Microphone)  â”‚    â”‚    (WebSocket)   â”‚    â”‚   (Real-time)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cartesia TTS   â”‚â—€â”€â”€â”€â”‚  Response Engine â”‚â—€â”€â”€â”€â”‚ Deepgram STT   â”‚
â”‚  (Audio Output) â”‚    â”‚  (Gemini + RAG)  â”‚    â”‚ (Transcription) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ LlamaIndex VDB  â”‚
                       â”‚ (Gemini Embed)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tech Stack:**
- **LLM**: Google Gemini 1.5 Flash (Free)
- **Embeddings**: Gemini Embeddings (Free)  
- **STT**: Deepgram Nova-2
- **TTS**: Cartesia Sonic
- **RAG**: LlamaIndex with persistent vector store
- **Real-time**: Flask-SocketIO WebSockets

## ðŸ› ï¸ Configuration

Key settings in `app.py`:
```python
Settings.chunk_size = 512
Settings.chunk_overlap = 50
similarity_top_k = 5
model_name = "gemini-1.5-flash"
```

## ðŸš€ Deployment

**Development:**
```bash
python app.py  # http://localhost:5000
```

**Production:**
```bash
pip install gunicorn
gunicorn --worker-class eventlet -w 1 --bind 0.0.0.0:5000 app:app
```

## ðŸ”§ Troubleshooting

- **Microphone issues**: Ensure HTTPS in production, check browser permissions
- **Knowledge base errors**: Delete `query-engine-storage-free/` folder and restart
- **API errors**: Verify all API keys in `.env` file
- **Audio playback**: Check browser audio permissions

## ðŸ“ˆ Performance
- Response time: ~1-2 seconds
- Supports 10-50 concurrent users
- Real-time WebSocket communication
- Persistent vector storage

## ðŸ¤ Contributing

1. Fork repository
2. Create feature branch
3. Test voice interactions
4. Submit pull request

## ðŸ“„ License

MIT License

---

**Built with Gemini (Free) + Deepgram + Cartesia for cost-effective real-time voice AI**
